{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch = 30\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3d60cb0a3944d2b5093a3cf2c3a47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4bf905d868402a90b68e22da093479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372b332a7a874b83a3965de33f15ef47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d69329902a840df9e0044540f6986cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans = torchvision.transforms.ToTensor()\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.MNIST(\n",
    "            'mnist_data', train=True, download=True, transform=trans\n",
    "            ), batch_size=batch_size\n",
    "            )\n",
    "val_data = torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.MNIST(\n",
    "            'mnist_data', train=False, download=True, transform=trans\n",
    "            ), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear1 = nn.Linear(3456, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tanh(self.conv1(x))\n",
    "        x = self.tanh(self.conv2(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        y_pred = model(images)\n",
    "        value, pred = torch.max(y_pred, 1)\n",
    "        total += y_pred.size(0)\n",
    "        correct += torch.sum(pred == labels)\n",
    "    return correct * 100 / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 26, 26]              30\n",
      "              Tanh-2            [-1, 3, 26, 26]               0\n",
      "            Conv2d-3            [-1, 6, 24, 24]             168\n",
      "              Tanh-4            [-1, 6, 24, 24]               0\n",
      "            Linear-5                   [-1, 10]          34,570\n",
      "================================================================\n",
      "Total params: 34,768\n",
      "Trainable params: 34,768\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.08\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "convnet = ConvNet()\n",
    "summary(convnet, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss:  0.06866645067930222 Val. Accuracy: 86.27999877929688\n",
      "Epoch: 2 Loss:  0.13885276019573212 Val. Accuracy: 85.95999908447266\n",
      "Epoch: 3 Loss:  0.1134258359670639 Val. Accuracy: 89.44999694824219\n",
      "Epoch: 4 Loss:  0.23833653330802917 Val. Accuracy: 82.19999694824219\n",
      "Epoch: 5 Loss:  0.1914588063955307 Val. Accuracy: 89.08000183105469\n",
      "Epoch: 6 Loss:  0.12360385060310364 Val. Accuracy: 89.56999969482422\n",
      "Epoch: 7 Loss:  0.13891775906085968 Val. Accuracy: 89.7699966430664\n",
      "Epoch: 8 Loss:  0.1110406443476677 Val. Accuracy: 89.33000183105469\n",
      "Epoch: 9 Loss:  0.08644136786460876 Val. Accuracy: 87.41999816894531\n",
      "Epoch: 10 Loss:  0.17617720365524292 Val. Accuracy: 88.69999694824219\n",
      "Epoch: 11 Loss:  0.11897692084312439 Val. Accuracy: 87.08999633789062\n",
      "Epoch: 12 Loss:  0.07859304547309875 Val. Accuracy: 87.76000213623047\n",
      "Epoch: 13 Loss:  0.025874320417642593 Val. Accuracy: 88.2699966430664\n",
      "Epoch: 14 Loss:  0.06950537860393524 Val. Accuracy: 88.75\n",
      "Epoch: 15 Loss:  0.0964871272444725 Val. Accuracy: 89.26000213623047\n",
      "Epoch: 16 Loss:  0.09368100762367249 Val. Accuracy: 88.48999786376953\n",
      "Epoch: 17 Loss:  0.024851789698004723 Val. Accuracy: 86.97000122070312\n",
      "Epoch: 18 Loss:  0.1639283448457718 Val. Accuracy: 88.70999908447266\n",
      "Epoch: 19 Loss:  0.07044270634651184 Val. Accuracy: 88.41000366210938\n",
      "Epoch: 20 Loss:  0.1724385768175125 Val. Accuracy: 87.97000122070312\n",
      "Epoch: 21 Loss:  0.10498956590890884 Val. Accuracy: 87.08000183105469\n",
      "Epoch: 22 Loss:  0.31062307953834534 Val. Accuracy: 86.08000183105469\n",
      "Epoch: 23 Loss:  0.04168273136019707 Val. Accuracy: 86.7699966430664\n",
      "Epoch: 24 Loss:  0.13097409904003143 Val. Accuracy: 86.3499984741211\n",
      "Epoch: 25 Loss:  0.015024064108729362 Val. Accuracy: 88.02999877929688\n",
      "Epoch: 26 Loss:  0.03877408429980278 Val. Accuracy: 88.08999633789062\n",
      "Epoch: 27 Loss:  0.025727635249495506 Val. Accuracy: 86.83999633789062\n",
      "Epoch: 28 Loss:  0.07297633588314056 Val. Accuracy: 87.12000274658203\n",
      "Epoch: 29 Loss:  0.06641902774572372 Val. Accuracy: 85.88999938964844\n",
      "Epoch: 30 Loss:  0.09786895662546158 Val. Accuracy: 87.87000274658203\n",
      "Wall time: 13min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimizer = optim.Adam(convnet.parameters(), lr=learning_rate)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "for n in range(epoch):\n",
    "    for i, (images, labels) in enumerate(train_data):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = convnet(images)\n",
    "        loss = cross_entropy(prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    accuracy = float(validate(convnet, val_data))\n",
    "    print(\"Epoch:\", n+1, \"Loss: \", float(loss.data), \"Val. Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model is trying to reduce the loss with varying validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
