{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch = 30\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98b67c9b8f94cff812d12cef40a71b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84129801b1447a4a9f69ea6ea1049c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e8dd2cf8fb4063acfdbfaede10d11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550c902ac91940e5b2586dd0374d3e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans = torchvision.transforms.ToTensor()\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.MNIST(\n",
    "            'mnist_data', train=True, download=True, transform=trans\n",
    "            ), batch_size=batch_size\n",
    "            )\n",
    "val_data = torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.MNIST(\n",
    "            'mnist_data', train=False, download=True, transform=trans\n",
    "            ), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1)\n",
    "        self.maxpool1 = nn.MaxPool2d((2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1)\n",
    "        self.maxpool2 = nn.MaxPool2d((2,2))\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear1 = nn.Linear(150, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.tanh(self.conv1(x)))\n",
    "        x = self.maxpool2(self.tanh(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        y_pred = model(images)\n",
    "        value, pred = torch.max(y_pred, 1)\n",
    "        total += y_pred.size(0)\n",
    "        correct += torch.sum(pred == labels)\n",
    "    return correct * 100 / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 26, 26]              30\n",
      "              Tanh-2            [-1, 3, 26, 26]               0\n",
      "         MaxPool2d-3            [-1, 3, 13, 13]               0\n",
      "            Conv2d-4            [-1, 6, 11, 11]             168\n",
      "              Tanh-5            [-1, 6, 11, 11]               0\n",
      "         MaxPool2d-6              [-1, 6, 5, 5]               0\n",
      "            Linear-7                   [-1, 10]           1,510\n",
      "================================================================\n",
      "Total params: 1,708\n",
      "Trainable params: 1,708\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "convnet = ConvNet()\n",
    "summary(convnet, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss:  0.12514452636241913 Val. Accuracy: 95.05000305175781\n",
      "Epoch: 2 Loss:  0.07508008927106857 Val. Accuracy: 96.16000366210938\n",
      "Epoch: 3 Loss:  0.02775716222822666 Val. Accuracy: 96.37999725341797\n",
      "Epoch: 4 Loss:  0.02378271147608757 Val. Accuracy: 96.7300033569336\n",
      "Epoch: 5 Loss:  0.06893365830183029 Val. Accuracy: 96.51000213623047\n",
      "Epoch: 6 Loss:  0.06561765819787979 Val. Accuracy: 96.37999725341797\n",
      "Epoch: 7 Loss:  0.018896516412496567 Val. Accuracy: 96.69000244140625\n",
      "Epoch: 8 Loss:  0.035781122744083405 Val. Accuracy: 96.72000122070312\n",
      "Epoch: 9 Loss:  0.020696386694908142 Val. Accuracy: 96.69000244140625\n",
      "Epoch: 10 Loss:  0.04571831226348877 Val. Accuracy: 96.72000122070312\n",
      "Epoch: 11 Loss:  0.04973458871245384 Val. Accuracy: 96.80999755859375\n",
      "Epoch: 12 Loss:  0.04461900144815445 Val. Accuracy: 96.68000030517578\n",
      "Epoch: 13 Loss:  0.09133164584636688 Val. Accuracy: 96.72000122070312\n",
      "Epoch: 14 Loss:  0.1170617863535881 Val. Accuracy: 96.88999938964844\n",
      "Epoch: 15 Loss:  0.06270679086446762 Val. Accuracy: 96.97000122070312\n",
      "Epoch: 16 Loss:  0.047327395528554916 Val. Accuracy: 96.63999938964844\n",
      "Epoch: 17 Loss:  0.014809129759669304 Val. Accuracy: 96.83999633789062\n",
      "Epoch: 18 Loss:  0.051471855491399765 Val. Accuracy: 96.75\n",
      "Epoch: 19 Loss:  0.06002502888441086 Val. Accuracy: 96.80999755859375\n",
      "Epoch: 20 Loss:  0.0873996689915657 Val. Accuracy: 96.31999969482422\n",
      "Epoch: 21 Loss:  0.07229167222976685 Val. Accuracy: 96.13999938964844\n",
      "Epoch: 22 Loss:  0.07015674561262131 Val. Accuracy: 96.5\n",
      "Epoch: 23 Loss:  0.06978669762611389 Val. Accuracy: 96.1500015258789\n",
      "Epoch: 24 Loss:  0.06693770736455917 Val. Accuracy: 96.37000274658203\n",
      "Epoch: 25 Loss:  0.1015641838312149 Val. Accuracy: 96.56999969482422\n",
      "Epoch: 26 Loss:  0.10442840307950974 Val. Accuracy: 96.08000183105469\n",
      "Epoch: 27 Loss:  0.0949859693646431 Val. Accuracy: 95.8499984741211\n",
      "Epoch: 28 Loss:  0.0397629514336586 Val. Accuracy: 96.08999633789062\n",
      "Epoch: 29 Loss:  0.06581955403089523 Val. Accuracy: 96.19000244140625\n",
      "Epoch: 30 Loss:  0.08715475350618362 Val. Accuracy: 96.44000244140625\n",
      "Wall time: 13min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimizer = optim.Adam(convnet.parameters(), lr=learning_rate)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "for n in range(epoch):\n",
    "    for i, (images, labels) in enumerate(train_data):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = convnet(images)\n",
    "        loss = cross_entropy(prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    accuracy = float(validate(convnet, val_data))\n",
    "    print(\"Epoch:\", n+1, \"Loss: \", float(loss.data), \"Val. Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that adding pooling layers reduced number parameters and increased the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
