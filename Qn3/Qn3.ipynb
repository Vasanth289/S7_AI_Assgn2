{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch = 30\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d4dabcb06746d294e5a8f5eb8fcab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\train-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabc9e4734ce48a4b6b01c7e46726613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ac6df55b154d808242ba1a60ae687d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d81f24a73814c688cc9dd00822eee67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting mnist_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to mnist_data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans = torchvision.transforms.ToTensor()\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.MNIST(\n",
    "            'mnist_data', train=True, download=True, transform=trans\n",
    "            ), batch_size=batch_size\n",
    "            )\n",
    "val_data = torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.MNIST(\n",
    "            'mnist_data', train=False, download=True, transform=trans\n",
    "            ), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1)\n",
    "        self.maxpool1 = nn.MaxPool2d((2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1)\n",
    "        self.maxpool2 = nn.MaxPool2d((2,2))\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(150, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        y_pred = model(images)\n",
    "        value, pred = torch.max(y_pred, 1)\n",
    "        total += y_pred.size(0)\n",
    "        correct += torch.sum(pred == labels)\n",
    "    return correct * 100 / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 26, 26]              30\n",
      "              ReLU-2            [-1, 3, 26, 26]               0\n",
      "         MaxPool2d-3            [-1, 3, 13, 13]               0\n",
      "            Conv2d-4            [-1, 6, 11, 11]             168\n",
      "              ReLU-5            [-1, 6, 11, 11]               0\n",
      "         MaxPool2d-6              [-1, 6, 5, 5]               0\n",
      "            Linear-7                   [-1, 10]           1,510\n",
      "================================================================\n",
      "Total params: 1,708\n",
      "Trainable params: 1,708\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "convnet = ConvNet()\n",
    "summary(convnet, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss:  0.05259706452488899 Val. Accuracy: 94.94999694824219\n",
      "Epoch: 2 Loss:  0.052410438656806946 Val. Accuracy: 94.94000244140625\n",
      "Epoch: 3 Loss:  0.0477810874581337 Val. Accuracy: 94.76000213623047\n",
      "Epoch: 4 Loss:  0.038834888488054276 Val. Accuracy: 94.7699966430664\n",
      "Epoch: 5 Loss:  0.06164509803056717 Val. Accuracy: 94.69999694824219\n",
      "Epoch: 6 Loss:  0.0478551909327507 Val. Accuracy: 94.0199966430664\n",
      "Epoch: 7 Loss:  0.08872967213392258 Val. Accuracy: 95.6500015258789\n",
      "Epoch: 8 Loss:  0.3225192129611969 Val. Accuracy: 95.4000015258789\n",
      "Epoch: 9 Loss:  0.15344081819057465 Val. Accuracy: 95.95999908447266\n",
      "Epoch: 10 Loss:  0.223435178399086 Val. Accuracy: 95.08999633789062\n",
      "Epoch: 11 Loss:  0.1052035242319107 Val. Accuracy: 95.69000244140625\n",
      "Epoch: 12 Loss:  0.06465202569961548 Val. Accuracy: 95.98999786376953\n",
      "Epoch: 13 Loss:  0.12556135654449463 Val. Accuracy: 95.2699966430664\n",
      "Epoch: 14 Loss:  0.010636642575263977 Val. Accuracy: 95.8499984741211\n",
      "Epoch: 15 Loss:  0.0344492569565773 Val. Accuracy: 95.70999908447266\n",
      "Epoch: 16 Loss:  0.09161107242107391 Val. Accuracy: 96.06999969482422\n",
      "Epoch: 17 Loss:  0.03477632626891136 Val. Accuracy: 96.66999816894531\n",
      "Epoch: 18 Loss:  0.012446939945220947 Val. Accuracy: 97.04000091552734\n",
      "Epoch: 19 Loss:  0.03486403450369835 Val. Accuracy: 96.47000122070312\n",
      "Epoch: 20 Loss:  0.01697366125881672 Val. Accuracy: 96.33000183105469\n",
      "Epoch: 21 Loss:  0.04245806112885475 Val. Accuracy: 97.05999755859375\n",
      "Epoch: 22 Loss:  0.02917303889989853 Val. Accuracy: 96.29000091552734\n",
      "Epoch: 23 Loss:  0.02995985746383667 Val. Accuracy: 96.9000015258789\n",
      "Epoch: 24 Loss:  0.022003857418894768 Val. Accuracy: 96.52999877929688\n",
      "Epoch: 25 Loss:  0.008078806102275848 Val. Accuracy: 96.63999938964844\n",
      "Epoch: 26 Loss:  0.009919246658682823 Val. Accuracy: 96.73999786376953\n",
      "Epoch: 27 Loss:  0.01386487577110529 Val. Accuracy: 96.5\n",
      "Epoch: 28 Loss:  0.026468627154827118 Val. Accuracy: 96.77999877929688\n",
      "Epoch: 29 Loss:  0.020659085363149643 Val. Accuracy: 96.61000061035156\n",
      "Epoch: 30 Loss:  0.00673458818346262 Val. Accuracy: 96.87000274658203\n",
      "Wall time: 8min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimizer = optim.Adam(convnet.parameters(), lr=learning_rate)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "for n in range(epoch):\n",
    "    for i, (images, labels) in enumerate(train_data):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = convnet(images)\n",
    "        loss = cross_entropy(prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    accuracy = float(validate(convnet, val_data))\n",
    "    print(\"Epoch:\", n+1, \"Loss: \", float(loss.data), \"Val. Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that ReLU activation function gives better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
